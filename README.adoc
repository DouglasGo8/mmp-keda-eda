= KEDA _Kubernetes Based Event Driven Autoscaling_

== Links

- https://kubernetes.io/docs/tutorials/hello-minikube/[Hello Minikube]
- https://github.com/kedacore/keda/releases[KEDA Releases]
- https://www.techbeatly.com/how-to-access-applications-deployed-in-minikube-kubernetes-cluster/[How to access applications deployed in minikube Kubernetes cluster using NodePort]

== Concepts

. KEDA _(Kubernetes-based Event Driven Autoscaling)_ is a popular open-source that enables the dynamic scaling of Kubernetes workloads based on event-driven metrics, it is designed to work with a range of event sources, including Azure Event Hubs, Apache Kafka, Rabbit MQ and many more. *_It enabled K8's clusters to scale workloads up or down_* in response to event-driven metrics, such as the number of messages in a queue or the size of a file in a storage account

=== How to KEDA works

. Based on Agent - Keda can activate and deactivate K8s Deployments to scale to and from zero on no events.
This is one of the primary roles of keda, *_based on operator_* container that runs when you install KEDA

. Metrics - Keda acts as K8s metrics server that exposes rich event data like queue length or stream lag to the HPA _(Horizontal Pod Autoscaler)_ to drive scale out.
It is up to the deployment to consume the events directly from the source.
This preservers rich event integration and enables gestures like completing or abandoning queue messages to work out of the box.
The metric serving is the primary role of the _keda-operator-metrics-apiserver_ container that runs whe you install KEDA

.KEDA Architecture
image::thumb/excalidraw/keda-arch.png[]

. ScaleObject and ScaleJob - are K8's resources used for scaling applications.
However, they have different use cases and functionality, basic a _ScaleObject_ is a resource used for autoscaling a K8s Deployment or Stateful object, based on metrics provided by the external services like RabbitMQ, AWS SQS etc, _ScaleJob_ on the other hand, is a K8s extension that allows for an automatic scaling of K8s job, with ScaleJob we can create and manages a set of identical job objects, each which will performs a particular task.

== Install Keda

[source,bash]
----
# Add Helm Repo
# Must be on keda Namespace
helm repo add kedacore https://kedacore.github.io/charts
helm repo update
k create ns keda
kubens keda
#
helm install keda kedacore/keda
# Remove Keda
helm uninstall keda
----

.Scaleobject Specification
[source,yaml]
----
apiVersion: keda.sh/v1alpha1
kind: ScaleObject
metadata:
  name: [scaled-object-name]
spec:
  # Section the specifies the Kubernetes resource that should be scaled by KEDA
  scaleTargetRef:
    apiVersion: [api-version-of-target-resource]  # Optional. Default: apps/v1
    kind:       [kind-of-target-resource]         # Optional. Default: Deployment
    name:       [name-of-target-resource]         # Mandatory. Must be in the same namespace as the ScaledObject
    envSourceContainerName: [container-name]      # Optional. Default: .spec.template.spec.containers[0]
  pollingInterval: 30                             # Optional. Default: 30 seconds
  cooldownPeriod: 300                             # Optional. Default: 300 seconds
  idleReplicaCount: 0                             # Optional. Default: ignored, must be less than replicaCount
  minReplicaCount: 1                              # Optional. Default: 0 event
  maxReplicaCount: 100                            # Optional. Default: 100
  fallback:
    failureThreshold: 3                           # Mandatory if fallback section is included
    replicas: 6                                   # Mandatory if fallback section is included
  advanced:
    restoreToOriginalReplicaCount: true/false     # Optional. Default: false
    horizontalPodAutoscalerConfig:                # Optional. Section to specify HPA related options
      name: [name-of-hpa-resource]                # Optional. Default: keda-hpa-[scaled-object-name]
      behavior:
        scaleDown:
          stabilizationWindowSeconds: 300
          policies:
          - type: Percent
            value: 100
            periodSeconds: 15
  triggers:
  # [list of triggers to active scaling of the target resource]
----

.RabbitMQ Kubernetes Cluster Installation
[source,bash]
----
k apply -f "https://github.com/rabbitmq/cluster-operator/releases/latest/download/cluster-operator.yml"
----

. Use Jib to create and push docker to containers use as reference https://github.com/DouglasGo8/mmp-rabbitmq-quarkus-camel to use Apache Camel to Produce/Consumer

.K8s Deployment Object
[source,yaml]
----
apiVersion: apps/v1
kind: Deployment
metadata:
  name: quarkus-rabbitmq-basic-consumer
spec:
  selector:
    matchLabels:
      app: quarkus-rabbitmq-basic-consumer
  template:
    metadata:
      labels:
        app: quarkus-rabbitmq-basic-consumer
    spec:
      containers:
        - name: quarkus-rabbitmq-basic-consumer
          image: douglasdb/quarkus-rabbitmq-basic-consumer
          imagePullPolicy: IfNotPresent
----

.KEDA ScaleObject to quarkus-rabbitmq-basic-consumer resource
[source,yaml]
----
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: rabbitmq-scaleobject
  namespace: default
spec:
  scaleTargetRef:
    name: quarkus-rabbitmq-basic-consumer
  pollingInterval: 5 # Optional. Default: 30s
  cooldownPeriod: 120 # Optional. Default: 300s
  maxReplicaCount: 20 # Optional. Default: 100
  triggers:
    - type: rabbitmq
      metadata:
        protocol: amqp
        queueName: queue001
        mode: QueueLength
        value: "5"
        host: amqp://guest:guest@ipOrservice:5672 # only test effect
----

[source,bash]
----
k get deploy # will show READY 0/0
----

.Sample of Result
image::thumb/pic/QueueLengthScaler.png[]

.KEDA with cron Job
[source,yaml]
----
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: rabbitmq-scaledobject-cron
  namespace: default
spec:
  scaleTargetRef:
    name: quarkus-rabbitmq-basic-consumer
  cooldownPeriod: 60
  advanced:
    restoreToOriginalReplicaCount: true
  triggers:
  - type: cron
    metadata:
      timezone: America/Sao_Paulo
      start: 15 6 * * *
      end: 18 6 * * *
      desiredReplicas: "2"
  - type: cron
    metadata:
      timezone: America/Sao_Paulo
      start: 10 6 * * *
      end: 12 6 * * *
      desiredReplicas: "5"


----